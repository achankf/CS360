\begin{enumerate}
\item
Let $J = I(\{ab\}, \{ \frac{w}{awb}, \frac{w_1,w_2}{aw_1w_2b} \})$.

\begin{claim}
$L(G) \subseteq J$
\end{claim}
\begin{proof}
Suppose $w \in L(G)$, so $w$ has a parse tree $T$.
The idea is to ``compressed" the parse tree for $w$ in a bottom-up fashion, so that all variables in the tree are replaced by terminals along the way -- eventually the root will contain $w$.
Notice that $ab$ must be in the very bottom of $T$, otherwise that level (say, $i$-th) has at least one $S$, and $T$ has one more level ($(i+1)$-th).
Therefore, $ab$ must be the possible starting nodes of the new graph.

{\bf Base Case}
If $w = ab$, which is in the base set of $J$, so we are okay.

{\bf Inductive Step}
We have recovered portions of $w$ at the $i$-th level of the original parse tree, called them $x_j, x_k \in L(G)$.
By inductive hypothesis, those words are still in $J$.
Consider $i-1$-th level in $T$ (we are going towards the root of $T$).
So, there can be many $S$'s but there are only 3 cases that we need to consider.
\begin{itemize}
\item
$S \rightarrow ab$: this only happens the in bottom of $T$, and is obviously a word in $J$.
\item
$S \rightarrow aSb$: we compressed the parse tree by replacing $S$ with its children, which is $x_j$, to get $ax_jb$, which is still a word in $J$ because we can apply one of $J$'s rules $\frac{x_j}{ax_jb}$.
\item
$S \rightarrow aSSb$: similarly, we get $ax_jx_kb$. It is still in $J$ due to the rule $\frac{x_j,x_k}{ax_jx_kb}$.
\end{itemize}
Therefore, by induction the claim holds.
\end{proof}
\begin{claim}
$J \subseteq L(G)$
\end{claim}
\begin{proof}
Suppose $w \in J$.
Since $w$ is generated inductively and is finite, so $w$ has a generating sequence that starts from $ab$ and ends with the generation of $w$.
Notice all words that are used by the $i$-th step must be generated by the steps before it.

{\bf Base Case}
If $w = ab$, which is in $L(G)$, so we are okay.

{\bf Inductive Step}
Suppose the generating sequence has generated $y_j, y_k \in J$ up to the ($i-1$)-th step.
By induction hypothesis, they are still valid words in $L(G)$.
For the $i$-th sequence, we have to consider 2 cases.
\begin{itemize}
\item
$ab$ (using elements in the base set): it is clearly a word in $L(G)$.
\item
$\frac{w}{awb}$: so we have $ay_jb$, which is closed under $L(G)$ by the rule $S \rightarrow aSb$.
\item
$\frac{w_1,w_2}{aw_1w_2b}$: so we have $ay_jy_kb$, which is closed under $L(G)$ by the rule $S \rightarrow aSSb$.
\end{itemize}
Therefore, by induction the claim holds.
\end{proof}
Together we have $L(G) = I(\{ab\}, \{ \frac{w}{awb}, \frac{w_1,w_2}{aw_1w_2b} \})$, as required.
\done
\item
Let's prove by structural induction on $I(\{ab\},\{ \frac{w}{awb}, \frac{w_1,w_2}{aw_1w_2b} \})$.

{\bf Base Case}
Clearly, $ab$ has 1 $a$ and 1 $b$, so $\#_a(ab) = \#_b(ab)$.

{\bf Inductive Step}
Suppose $w_1, w_2 \in L(G)$.
By the inductive hypothesis, $\#_a(w_1) = \#_b(w_1)$ and $\#_a(w_2) = \#_b(w_2)$.
There are 2 cases, one for each operation:
\begin{itemize}
\item
$\frac{w_1}{aw_1b}$, so the result is $w = aw_1b$.
Thus,
\begin{align*}
\#_a(w) &= 1 + \#_a(w_1) \\
\#_b(w) &= 1 + \#_b(w_1) \\
\implies \#_a(w) &= \#_b(w)
\end{align*}
\item
$\frac{w_1,w_2}{aw_1w_2b}$, so the result is $w = aw_1w_2b$.
Thus,
\begin{align*}
\#_a(w) &= 1 + \#_a(w_1) + \#_a(w_2) \\
\#_b(w) &= 1 + \#_b(w_1) + \#_b(w_2) \\
\implies \#_a(w) &= \#_b(w)
\end{align*}
\end{itemize}
Therefore, by structural induction, for every $w \in L(G)$, $\#_a(w) = \#_b(w)$.
\done
\item
\done
\item
\done
\end{enumerate}
